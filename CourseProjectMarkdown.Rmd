---
title: "Applied Machine Learning Course Project"
author: "Pat Mitoraj"
date: "January 15, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
The goal of this project is to predict whether study participants performed a barbell lift correctly. The data in the study is based on the Weight Lifting Excercise Dataset from the Human Activity Recognition Project. In order to make these predicitions, a random forest model was created using Principal Component Analysis as well as cross validation.

##Data Cleaning
First, the training and testing sets were downloaded along with the caret and kernlab packages. 
```{r}
training<-read.csv("C:\\Users\\Pat Mitoraj\\Documents\\R Programming Course\\Practical Machine Learning\\Course Project\\pml-training.csv")
testing<-read.csv("C:\\Users\\Pat Mitoraj\\Documents\\R Programming Course\\Practical Machine Learning\\Course Project\\pml-training.csv")
library(caret)
library(kernlab)
```
The original training and testing datasets each had 161 columns. The first step in analyzing these datasets was to run a summary of the columns:
```{r} 
summary(training)
```
What this summary shows is that many of the columns either contained decrptive information not useful for predicting or NA values. These columns were then removed from both the training and test datasets.
```{r}
training<-training[,-c(1:7,12:16,19,22,25,69:74,87:92,95,98,101,125:130,133,136,139)]
training<-training[,-c(5:21,35:44,54:62,66:71,73:82,95:100,102:111)]
testing<-testing[,-c(1:7,12:16,19,22,25,69:74,87:92,95,98,101,125:130,133,136,139)]
testing<-testing[,-c(5:21,35:44,54:62,66:71,73:82,95:100,102:111)]
```
After these columns were removed, there were 53 columns in both the training and testing sets.

##Model Creation
The first step in developing a predictive model was to determine how highly correlated the variables were with each other. This was done by creating a matrix with the correlation between each combination of variables in the training set.

```{r}
M<-abs(cor(training[,-53]))
diag(M)<-0
which(M>.8,arr.ind=T)
```
The results of this analysis show that many of the variables in the dataset were highly correlated with each other. As a result, principal component anlysis was used in order to determine the best combination of these predictors to include the final model. Next, a function for cross validation is written that will be included in the predictive model:
```{r}
train_control <- trainControl(method="cv", number=10, savePredictions = TRUE)
```
The validation used is 10 fold cross validation, which will improve the accuracy estimate of the model. 10 folds were used as it gives a good balance between bias and variance; fewer folds would have resulted in more bias, while including more folds would have increased the variance. Finally, the model is trained on the testing set:
``` {r, cache=TRUE}
set.seed(2323)
modFit<-train(classe~.,training,method="rf",preProcess=c("pca"),
              trControl=train_control)
```
##Predictions
Based on the training data, an accuracy of 98% is expected:
```{r}
getTrainPerf(modFit)
```
The last step is to use the model to make predictions on the testing set:
```{r}
predictions<-predict(modFit,testing)
predictions
```
